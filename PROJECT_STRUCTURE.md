# Project Structure

```
pp1/
â”‚
â”œâ”€â”€ backend/                          # Backend API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                       # Flask application entry point
â”‚   â”œâ”€â”€ database.py                  # Database models (User, Violation, Post)
â”‚   â”œâ”€â”€ config.py                    # Configuration settings
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # ML models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ detector.py             # Hate speech detector class
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                      # API endpoints
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ api.py                  # API routes (analyze, users, violations, stats)
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ preprocessing.py        # Text preprocessing utilities
â”‚       â””â”€â”€ helpers.py              # Helper functions
â”‚
â”œâ”€â”€ frontend/                         # Frontend Dashboard
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py                       # Streamlit dashboard application
â”‚
â”œâ”€â”€ ml_model/                         # Machine Learning
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train_model.py              # Model training script
â”‚   â”œâ”€â”€ hate_speech_model.pkl       # Trained model (generated)
â”‚   â””â”€â”€ vectorizer.pkl              # TF-IDF vectorizer (generated)
â”‚
â”œâ”€â”€ data/                            # Data files
â”‚   â””â”€â”€ sample_data.csv             # Sample training dataset
â”‚
â”œâ”€â”€ .venv/                           # Virtual environment (generated)
â”‚
â”œâ”€â”€ instance/                        # Flask instance folder (generated)
â”‚   â””â”€â”€ hate_speech_detection.db   # SQLite database (generated)
â”‚
â”œâ”€â”€ .env                            # Environment variables
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Project overview
â”œâ”€â”€ INSTALLATION.md                 # Installation guide
â”œâ”€â”€ PROJECT_STRUCTURE.md            # This file
â”‚
â”œâ”€â”€ setup.ps1                       # Quick setup script
â”œâ”€â”€ start_backend.ps1               # Start backend server
â”œâ”€â”€ start_frontend.ps1              # Start frontend dashboard
â””â”€â”€ test_system.py                  # System test script
```

## Component Details

### Backend (Flask API)

#### `app.py`
- Main Flask application
- Initializes database and registers routes
- Provides root endpoint with API information

#### `database.py`
- SQLAlchemy ORM models:
  - **User**: Tracks social media users, warnings, suspension status
  - **Violation**: Records hate speech incidents with category and confidence
  - **Post**: Stores all analyzed content

#### `models/detector.py`
- `HateSpeechDetector` class
- Loads trained ML model
- Analyzes text and returns:
  - Hate speech prediction (True/False)
  - Confidence score (0-1)
  - Category (racial, gender, religious, etc.)
  - Detected language

#### `routes/api.py`
API endpoints:
- `POST /api/analyze` - Analyze text for hate speech
- `GET /api/users` - Get all users
- `GET /api/users/<id>` - Get specific user details
- `POST /api/users/<id>/warn` - Warn a user
- `POST /api/users/<id>/suspend` - Suspend a user
- `POST /api/users/<id>/unsuspend` - Unsuspend a user
- `GET /api/violations` - Get all violations (with pagination)
- `GET /api/statistics` - Get platform statistics

#### `utils/preprocessing.py`
- `TextPreprocessor` class:
  - Text cleaning (URLs, mentions, special chars)
  - Stopword removal
  - Lemmatization
  - Language detection
- `categorize_hate_speech()` function

#### `config.py`
Configuration constants:
- API settings
- Database URL
- Model paths
- Moderation settings
- Feature flags

### Frontend (Streamlit Dashboard)

#### `app.py`
Multi-page Streamlit application:

**Pages:**
1. **Dashboard** (ğŸ )
   - Key metrics (users, violations, posts)
   - Pie chart: Clean vs Hate Speech posts
   - Bar chart: Violations by category
   - Recent violations table

2. **Text Analyzer** (ğŸ”)
   - Real-time text analysis
   - User input (ID, username, text)
   - Results display with confidence score
   - Action feedback (warning/suspension)

3. **User Management** (ğŸ‘¥)
   - User list with filters
   - Sort and search functionality
   - Manual moderation actions:
     - Warn user
     - Suspend user
     - Unsuspend user
   - User details and violation history

4. **Violations Log** (ğŸ“Š)
   - Complete violations table
   - Filter by category and action
   - Pagination support
   - CSV export functionality

5. **About** (â„¹ï¸)
   - System overview
   - Feature descriptions
   - Technology stack
   - How it works
   - System status check

### ML Model

#### `train_model.py`
- `HateSpeechModelTrainer` class
- Creates or loads training dataset
- Text preprocessing pipeline
- Trains ensemble model:
  - Logistic Regression
  - Random Forest
  - Multinomial Naive Bayes
  - Voting Classifier (soft voting)
- TF-IDF vectorization
- Model evaluation and metrics
- Saves trained model and vectorizer

### Database Schema

#### Users Table
```
- id (Integer, Primary Key)
- username (String, Unique)
- email (String, Unique)
- warning_count (Integer)
- is_suspended (Boolean)
- suspended_at (DateTime)
- created_at (DateTime)
```

#### Violations Table
```
- id (Integer, Primary Key)
- user_id (Foreign Key â†’ users.id)
- content (Text)
- category (String)
- confidence_score (Float)
- language (String)
- timestamp (DateTime)
- action_taken (String)
```

#### Posts Table
```
- id (Integer, Primary Key)
- user_id (Foreign Key â†’ users.id)
- content (Text)
- is_hate_speech (Boolean)
- confidence_score (Float)
- created_at (DateTime)
```

## Data Flow

### Analysis Request Flow

1. **User Input** â†’ Frontend form (Text Analyzer page)
2. **API Request** â†’ `POST /api/analyze` with text, user_id, username
3. **Preprocessing** â†’ Clean and normalize text
4. **Detection** â†’ ML model predicts hate speech
5. **Database** â†’ Record violation (if hate speech detected)
6. **User Update** â†’ Increment warnings, check suspension threshold
7. **Response** â†’ Return results with action taken
8. **Display** â†’ Show results on frontend

### Statistics Flow

1. **Request** â†’ Frontend Dashboard or API call
2. **Query** â†’ Aggregate data from database
3. **Calculate** â†’ Compute metrics and percentages
4. **Response** â†’ Return statistics JSON
5. **Visualize** â†’ Display charts and metrics

## Key Features

### Automated Moderation
- Warning system with configurable threshold
- Automatic suspension after max warnings
- Manual moderation override options

### Categorization
- Racial hate speech
- Gender-based discrimination
- Religious intolerance
- Homophobic content
- General offensive language

### Multilingual Support
- Language detection using langdetect
- Support for multiple languages
- Extensible to additional languages

### Performance Monitoring
- Real-time statistics
- Violation tracking
- User behavior analytics
- Category-wise breakdown

## Extension Points

### Adding New Categories
1. Update `HATE_CATEGORIES` in `utils/preprocessing.py`
2. Update `CATEGORIES` in `config.py`
3. Retrain model with labeled examples

### Adding New Languages
1. Update `SUPPORTED_LANGUAGES` in `config.py`
2. Train model with multilingual dataset
3. Update preprocessing to handle language-specific rules

### Custom Actions
1. Add new action logic in `routes/api.py`
2. Update database schema if needed
3. Add UI controls in frontend

### Integration
- Use API endpoints to integrate with existing platforms
- Webhook support can be added for real-time notifications
- Batch processing endpoint can be added for bulk analysis

## Security Considerations

- Input validation and sanitization
- SQL injection prevention (SQLAlchemy ORM)
- XSS protection
- Rate limiting (add in production)
- Authentication/Authorization (JWT ready)
- HTTPS in production
- Environment variable for secrets

## Performance Optimization

- Database indexing on frequently queried fields
- Caching for statistics
- Batch processing for multiple texts
- Model optimization (quantization, distillation)
- Connection pooling
- Asynchronous processing for heavy tasks

## Testing

- Unit tests for preprocessing
- API endpoint tests
- Model accuracy evaluation
- Integration tests
- Load testing for production

## Monitoring

- Application logs
- Error tracking
- Performance metrics
- User activity analytics
- Model performance monitoring
